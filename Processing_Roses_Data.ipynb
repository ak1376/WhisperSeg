{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhisperSeg Application to Rose's Canary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install the required packages. This isn't an exhaustive list. For the exhaustive list, please refer to \"requirements.txt\" in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (4.42.3)\n",
      "Requirement already satisfied: ctranslate2 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (4.3.1)\n",
      "Requirement already satisfied: ipywidgets in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (8.1.3)\n",
      "Requirement already satisfied: tqdm in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (4.65.0)\n",
      "Requirement already satisfied: scipy in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (1.23.5)\n",
      "Requirement already satisfied: librosa in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (0.10.0.post2)\n",
      "Requirement already satisfied: matplotlib in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (3.7.1)\n",
      "Requirement already satisfied: filelock in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: setuptools in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ctranslate2) (66.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipywidgets) (8.12.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (0.2)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: pooch<1.7,>=1.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (0.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (4.5.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: appnope in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: backcall in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /Users/ananyakapoor/opt/anaconda3/envs/Canary_Deep_Learning/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers ctranslate2 ipywidgets tqdm scipy numpy librosa matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from model import WhisperSegmenterFast\n",
    "from audio_utils import WhisperSegFeatureExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we will define the class that will be responsible for the processing of audio files. The main functions of this class are as follows:\n",
    "\n",
    " 1. segment_song: This will apply WhisperSeg to the audio file and will return the samples in the raw audio that correspond to song.\n",
    "\n",
    " 2. silencer: The samples of the raw wav file that correspond to noise (detected from the segment_song function above) will be replaced with silences. This returns a wav file with the noise replaced with silence\n",
    " \n",
    " 3. create_sonogram: create a sonogram of wav file returned from \"silencer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmenter: \n",
    "    def __init__(self, sr, segmenter, feature_extractor, min_frequency, spec_time_step, min_segment_length, eps, num_trials, wavfiles) -> None:\n",
    "        '''\n",
    "        Contains arguments necessary for WhisperSeg segmentation. For more details please refer to the readme of this repo\n",
    "        '''\n",
    "        self.sr = sr\n",
    "        self.segmenter = segmenter\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.min_frequency = min_frequency\n",
    "        self.spec_time_step = spec_time_step\n",
    "        self.min_segment_length = min_segment_length\n",
    "        self.eps = eps\n",
    "        self.num_trials = num_trials\n",
    "\n",
    "        self.wavfiles = wavfiles\n",
    "\n",
    "        # Will contain the detected song's onset times and offset times (parts of the wav file that correspond to song)\n",
    "        self.onset_list = []\n",
    "        self.offset_list = []\n",
    "\n",
    "    def segment_song(self, wavfile_path):\n",
    "        '''\n",
    "         Runs WhisperSeg on the audio file to determine the samples that correspond to song.\n",
    "        '''\n",
    "\n",
    "        onset_list = []\n",
    "        offset_list = []\n",
    "\n",
    "        audio, _ = librosa.load(wavfile_path, sr = self.sr)\n",
    "\n",
    "        prediction = self.segmenter.segment(audio, sr = sr, min_frequency = self.min_frequency, spec_time_step = self.spec_time_step,\n",
    "                        min_segment_length = self.min_segment_length, eps = self.eps, num_trials = self.num_trials)\n",
    "        \n",
    "        onset_list.append(prediction['onset'])\n",
    "        offset_list.append(prediction['offset'])\n",
    "\n",
    "        return self.sr*np.array(onset_list), self.sr*np.array(offset_list)\n",
    "\n",
    "    \n",
    "    def silencer(self, wavfile, samples_onsets, samples_offsets):\n",
    "        '''\n",
    "        This function will take a noisy wavfile and find the samples according to the samples_onsets and samples_offsets arrays. I will then replace all samples outside of these regions with zeros (silences)\n",
    "        '''\n",
    "\n",
    "        # Flatten the arrays to ensure they are one-dimensional\n",
    "        samples_onsets = np.array(samples_onsets).flatten()\n",
    "        samples_offsets = np.array(samples_offsets).flatten()\n",
    "\n",
    "        # Create an array of silence with the same shape and data type as the input wavfile\n",
    "        silenced_audio = np.zeros_like(wavfile)\n",
    "\n",
    "        # Copy detected regions to the silenced array\n",
    "        for start, end in zip(samples_onsets, samples_offsets):\n",
    "            # Explicitly convert start and end to integers to avoid indexing errors\n",
    "            start_idx = int(start)\n",
    "            end_idx = int(end)\n",
    "            silenced_audio[start_idx:end_idx] = wavfile[start_idx:end_idx]\n",
    "\n",
    "        return silenced_audio\n",
    "    \n",
    "    def create_sonogram(self, audio):\n",
    "        '''\n",
    "        Creates a sonogram corresponding to the silenced audio\n",
    "        '''\n",
    "        sonogram = self.feature_extractor(audio, sampling_rate=self.sr, padding = \"do_not_pad\" )[\"input_features\"][0]\n",
    "\n",
    "        return sonogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply this class to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 32000\n",
    "min_frequency = 0\n",
    "spec_time_step = 0.001\n",
    "min_segment_length = 0.005\n",
    "eps = 0.01\n",
    "num_trials = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the version of WhisperSeg finetuned on canaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = WhisperSegmenterFast( \"nccratliri/whisperseg-canary-ct2\", device=\"cpu\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More parameter initialization (for more details refer to the readme). We will also define the WhisperSeg object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values\n",
    "window_size = 15\n",
    "spec_width = 1000\n",
    "min_frequency = 0\n",
    "max_frequency = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = WhisperSegFeatureExtractor(sr, window_size / spec_width, min_frequency, max_frequency )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rose's data is structured first by Bird ID and then by day of data acquisition. We will extract the bird identities and the days of acquisition  and then apply WhisperSeg to the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be a single bird's filepath\n",
    "bird_paths = '/Users/AnanyaKapoor/Volumes/Extreme SSD/USA5207'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's extract the full filepaths of each wav file\n",
    "\n",
    "bird_filepaths = []\n",
    "\n",
    "for filename in os.listdir(bird_paths):\n",
    "    file_path = os.path.join(bird_paths, filename)\n",
    "    bird_filepaths.append(file_path)\n",
    "\n",
    "\n",
    "# For each wav file we will apply WhisperSeg, extract the cleaned up audio file, and then create a sonogram from that audio file. \n",
    "for bird_path in bird_filepaths:\n",
    "    # I first want to extract the days of data acquisiton (for example, day 38, 39 from USA5207)\n",
    "    all_days = bird_path\n",
    "\n",
    "    day_filepaths = []\n",
    "\n",
    "    for filename in os.listdir(all_days):\n",
    "        file_path = os.path.join(all_days, filename)\n",
    "        day_filepaths.append(file_path)\n",
    "\n",
    "    # Extract bird name\n",
    "    # Split the path by '/'\n",
    "    parts = all_days.split('/')\n",
    "\n",
    "    # Get the last element of the list\n",
    "    bird_name = parts[-1]\n",
    "    \n",
    "    os.makedirs(f'png_files/{bird_name}', exist_ok=True) # Will save images of the original wav file sonogram and the sonogram of the cleaned up audio file (used for visual inspection mostly)\n",
    "    os.makedirs(f'new_wav_files/{bird_name}', exist_ok=True) # Will save the new wav files. That way you can create new sonograms with different signal processing parameters. \n",
    "    \n",
    "    for day_path in day_filepaths:\n",
    "        # Extract each wav file filepath from each day folder. \n",
    "        filepaths = []\n",
    "\n",
    "        for filename in os.listdir(day_path):\n",
    "            file_path = os.path.join(day_path, filename)\n",
    "            filepaths.append(file_path)\n",
    "\n",
    "        # If there are no wav files in a folder then just skip that jawn. \n",
    "        if len(filepaths) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Define the segmenter (will process wav files within each day for a particular bird. Example: Will process all wav files from Day 38 of Bird USA5207)\n",
    "        seg_jawn = Segmenter(sr = sr, segmenter = segmenter, feature_extractor=feature_extractor, min_frequency=min_frequency, spec_time_step=spec_time_step, min_segment_length= min_segment_length, eps = eps, num_trials=num_trials, wavfiles= filepaths)\n",
    "\n",
    "        # For each wav file\n",
    "        for i in tqdm(np.arange(len(seg_jawn.wavfiles))):\n",
    "            # Extract the full filepath of the song\n",
    "            audio_path = seg_jawn.wavfiles[i]\n",
    "            # Load in the wav file \n",
    "            audio, _ = librosa.load(audio_path, sr = sr )\n",
    "            # Apply WhisperSeg to the data to extract the samples of the raw wav file that correspond to detected song\n",
    "            sample_onsets, sample_offsets = seg_jawn.segment_song(audio_path)\n",
    "            # Replace all the values for the samples in detected not song with 0s (silences)\n",
    "            silenced_audio = seg_jawn.silencer(audio, sample_onsets, sample_offsets)\n",
    "            # Create a sonogram from the original wav file\n",
    "            orig_spec = seg_jawn.create_sonogram(audio)\n",
    "            # Create a sonogram from the cleaned up audio file (silenced_audio)\n",
    "            silenced_spec = seg_jawn.create_sonogram(silenced_audio)\n",
    "\n",
    "            # Plotting (for every 50th wav file)\n",
    "            if i%50 == 0:\n",
    "\n",
    "                fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "                # Original audio spectrogram\n",
    "                axes[0].imshow(orig_spec, origin='lower', cmap='viridis')\n",
    "                axes[0].set_title('Original Audio Spectrogram')\n",
    "                axes[0].set_xlabel('Time')\n",
    "                axes[0].set_ylabel('Frequency Bin')\n",
    "\n",
    "                # Silenced audio spectrogram\n",
    "                axes[1].imshow(silenced_spec, origin='lower', cmap='viridis')\n",
    "                axes[1].set_title('Spectrogram from Audio with Noise Removed')\n",
    "                axes[1].set_xlabel('Time')\n",
    "                axes[1].set_ylabel('Frequency Bin')\n",
    "\n",
    "                # Display the plot\n",
    "                plt.tight_layout()\n",
    "\n",
    "                parts = day_path.split('/')\n",
    "                day_value = parts[-1]\n",
    "\n",
    "                os.makedirs(f'png_files/{bird_name}/day_{day_value}', exist_ok=True)\n",
    "\n",
    "                # Split the path by '/'\n",
    "                parts = audio_path.split('/')\n",
    "\n",
    "                # Get the last element of the list\n",
    "                last_part = parts[-1]\n",
    "\n",
    "                song_name = last_part.replace('.wav', '.png')\n",
    "\n",
    "                plt.savefig(f'png_files/{bird_name}/day_{day_value}/{song_name}')\n",
    "                plt.close()\n",
    "\n",
    "            # SAVE THE WAV FILES\n",
    "\n",
    "            ## Split the path by '/'\n",
    "            parts = audio_path.split('/')\n",
    "\n",
    "            ## Get the last element of the list\n",
    "            last_part = parts[-1]\n",
    "\n",
    "            os.makedirs(f'new_wav_files/{bird_name}/day_{day_value}', exist_ok=True)\n",
    "\n",
    "            write(f'new_wav_files/{bird_name}/day_{day_value}/{last_part}', sr, silenced_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Canary_Deep_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
